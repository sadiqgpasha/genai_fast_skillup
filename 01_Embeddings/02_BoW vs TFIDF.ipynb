{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b21c216-796e-4c4b-a1ca-a01eb4882cb8",
   "metadata": {},
   "source": [
    "# BoW vs TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97afeb-04a7-4821-a08d-3dbb63e41ff6",
   "metadata": {},
   "source": [
    "### What is Bag of Words (BoW)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f163d4-6875-4f35-8b30-4a58da2fdb3a",
   "metadata": {},
   "source": [
    "BoW is a simple technique to convert text into numerical features. It creates a vocabulary of all unique words in your corpus and represents each document as a vector of word counts.\n",
    "\n",
    "- It ignores grammar and word order.\n",
    "- It’s sparse and high-dimensional.\n",
    "- Example:\n",
    "\n",
    "For two sentences:\n",
    "- \"I love data\"\n",
    "- \"I love Python\"\n",
    "\n",
    "The vocabulary is: [\"I\", \"love\", \"data\", \"Python\"]\n",
    "The vectors become:\n",
    "- [1, 1, 1, 0]\n",
    "- [1, 1, 0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1636f5ff-981b-41ad-8725-548303e6532b",
   "metadata": {},
   "source": [
    "### What is TF-IDF?\n",
    "\n",
    "TF-IDF (Term Frequency–Inverse Document Frequency) improves on BoW by weighing words based on how important they are to a document in a corpus.\n",
    "\n",
    "- TF: How often a word appears in a document.\n",
    "- IDF: How rare the word is across all documents.\n",
    "- Common words like “the” get lower weights, while rare but meaningful words get higher weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c116cfb6-415f-42fd-b85a-5c3e1ef0cc41",
   "metadata": {},
   "source": [
    "### Key Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d68bd-bb6a-4712-bf9c-f5203716d6a3",
   "metadata": {},
   "source": [
    "|Feature|BoW|TF-IDF|\n",
    "|----|----|----|\n",
    "|Representation|Raw Word Counts| Weighted scores|\n",
    "|Captures Importance|No|Yes|\n",
    "|Handles Common Words|No|Downweights them|\n",
    "|Output|Sparse matrix|Sparse matrix with floatd weights|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6eb8c5-6be9-4492-a5e2-048b1bdf5f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/sgp/miniconda3/envs/dsenv/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/sgp/miniconda3/envs/dsenv/lib/python3.11/site-packages (from scikit-learn) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/sgp/miniconda3/envs/dsenv/lib/python3.11/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sgp/miniconda3/envs/dsenv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/sgp/miniconda3/envs/dsenv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0368dea-38cc-4459-bb39-684d10def7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Vocabulary: ['and' 'data' 'fun' 'is' 'love' 'python' 'science']\n",
      "BoW Matrix:\n",
      " [[0 1 0 0 1 0 1]\n",
      " [0 1 1 1 0 0 1]\n",
      " [1 1 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "#Sample Corpus\n",
    "\n",
    "corpus = [\n",
    "    \"I love data science\", \n",
    "    \"Data science is fun\", \n",
    "    \"I love python and data\"\n",
    "         ]\n",
    "\n",
    "# Bag of Words\n",
    "\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_matrix = bow_vectorizer.fit_transform(corpus)\n",
    "print(\"BoW Vocabulary:\", bow_vectorizer.get_feature_names_out())\n",
    "print(\"BoW Matrix:\\n\", bow_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1f2eea-ef50-4289-978c-2bd3179c677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Vocabulary: ['and' 'data' 'fun' 'is' 'love' 'python' 'science']\n",
      "TF-IDF Matrix:\n",
      " [[0.         0.48133417 0.         0.         0.61980538 0.\n",
      "  0.61980538]\n",
      " [0.         0.34520502 0.5844829  0.5844829  0.         0.\n",
      "  0.44451431]\n",
      " [0.5844829  0.34520502 0.         0.         0.44451431 0.5844829\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "print(\"\\nTF-IDF Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c183bb-f663-4955-a17a-28d792338bfa",
   "metadata": {},
   "source": [
    "### Practical Applications of BoW\n",
    "\n",
    "- Spam Detection:\n",
    "BoW can flag spam emails by identifying common spammy terms like “free,” “win,” or “urgent.”\n",
    "\n",
    "- Sentiment Analysis :\n",
    "In product or movie reviews, BoW helps classify text as positive or negative based on word frequency.\n",
    "\n",
    "- Topic Classification :\n",
    "News articles or documents can be categorized (e.g., sports, politics, tech) using BoW features.\n",
    "\n",
    "- Search Engines :\n",
    "Early search engines used BoW to match user queries with documents based on keyword overlap.\n",
    "\n",
    "- Plagiarism Detection :\n",
    "By comparing word frequency patterns, BoW can help detect copied content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448995d-6434-410e-93ab-7612c15ed816",
   "metadata": {},
   "source": [
    "### Practical Applications of TF-IDF:\n",
    "\n",
    "- Information Retrieval :\n",
    "TF-IDF is used to rank documents by relevance in search engines—highlighting documents that contain rare but important terms.\n",
    "\n",
    "- Keyword Extraction :\n",
    "Automatically identify the most important words in a document (e.g., for summarization or tagging).\n",
    "\n",
    "- Document Similarity:\n",
    "TF-IDF vectors can be used to measure how similar two documents are—useful in recommendation systems.\n",
    "\n",
    "\n",
    "- Chatbots and FAQ Matching:\n",
    "Match user queries to the most relevant predefined answers based on TF-IDF similarity.\n",
    "\n",
    "\n",
    "- Legal and Academic Text Mining:\n",
    "Extract meaningful terms from large corpora of legal or research documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdbe03-b362-4cd1-b274-704c85326232",
   "metadata": {},
   "source": [
    "### BoW for Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b83a5735-892f-40db-bb10-7536119de59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "['positive']\n",
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample data\n",
    "texts = [\"I love this movie\", \"This film was terrible\", \"Amazing acting\", \"Worst plot ever\"]\n",
    "labels = [\"positive\", \"negative\", \"positive\", \"negative\"]\n",
    "\n",
    "# Vectorize using BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Train a simple classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X, labels)\n",
    "\n",
    "# Predict on new text\n",
    "test = vectorizer.transform([\"Terrible acting\"])\n",
    "print(model.predict(test))  # Output: ['negative']\n",
    "\n",
    "test = vectorizer.transform([\"Worst acting\"])\n",
    "print(model.predict(test))  # Output: ['negative']\n",
    "\n",
    "test = vectorizer.transform([\"Amazing fighting\"])\n",
    "print(model.predict(test))  # Output: ['negative']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74fb336-f8f1-4ccf-9883-77262e08bdb2",
   "metadata": {},
   "source": [
    "### TF-IDF for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba396be-3183-4b86-9b68-6bbe8796cc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "['positive']\n",
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample data\n",
    "texts = [\"I love this movie\", \"This film was terrible\", \"Amazing acting\", \"Worst plot ever\"]\n",
    "labels = [\"positive\", \"negative\", \"positive\", \"negative\"]\n",
    "\n",
    "# Vectorize using TFIDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Train a simple classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X, labels)\n",
    "\n",
    "# Predict on new text\n",
    "test = vectorizer.transform([\"Terrible acting\"])\n",
    "print(model.predict(test))  # Output: ['negative']\n",
    "\n",
    "\n",
    "test = vectorizer.transform([\"Worst acting\"])\n",
    "print(model.predict(test))  # Output: ['negative']\n",
    "\n",
    "test = vectorizer.transform([\"Amazing fighting\"])\n",
    "print(model.predict(test))  # Output: ['negative']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5853383-bbe6-4c58-9053-fa048e7a3892",
   "metadata": {},
   "source": [
    "As you can see BoW & TFIDF are not  great approaches since they dont capture contextual meanings and semantic meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf46730-fd86-4a6c-9561-c28a063944a7",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "Semantic Meaning: \n",
    "This refers to the literal or dictionary definition of a word or phrase. It’s the core meaning that remains consistent regardless of where or how the word is used.\n",
    "- Example: The word “bank” semantically means a financial institution or the side of a river—both are valid dictionary meanings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8ab03-f801-4b25-8936-809c81cfb5f0",
   "metadata": {},
   "source": [
    "Contextual Meaning: \n",
    "This is the specific meaning a word takes on based on its surrounding words, situation, or usage. It’s how we figure out which semantic meaning is intended.\n",
    "- Example:\n",
    "- “He sat by the bank and watched the water.” → Here, “bank” means the side of a river.\n",
    "- “She deposited money in the bank.” → Now, “bank” refers to a financial institution.\n",
    "So, contextual meaning helps us choose the correct semantic meaning based on the situation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc76d2b-b34c-4fd7-8d38-bd80f70f89b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
